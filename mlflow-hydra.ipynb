{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4415f584",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Contra las mil cabezas de la Hidra\n",
    "============================\n",
    "\n",
    "\n",
    "¿Cómo llevar registro de experimentos con ayuda de MLFlow y Hydra?\n",
    "-----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d596ccf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ¿Quién soy?\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <h4 style=\"font-size:1.5em;margin:5px;\">Cristian Cardellino</h4>\n",
    "    <h5 style=\"font-style:normal;font-size:1em;margin:5px;\">Research en Mercado Libre - Docente en UNC</h5>\n",
    "    <div style=\"display:inline-block;margin-right:20px;\">\n",
    "        <img src=\"./img/me.jpg\" style=\"height:10em;width:auto;\"/>\n",
    "    </div>\n",
    "    <h6 style=\"font-style:normal;font-size:0.9em;margin:5px;\">\n",
    "        <a href=\"https://twitter.com/crscardellino\" style=\"color:royalblue;\" target=\"_blank\">@crscardellino</a> -\n",
    "        <a href=\"https://crscardellino.ar\" style=\"color:royalblue;\" target=\"_blank\">https://crscardellino.ar</a>\n",
    "    </h6>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2342e230",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Esquema de la charla\n",
    "\n",
    "1. [MLFlow](#MLFlow)\n",
    "1. [Hydra](#Hydra)\n",
    "1. [MLFlow + Hydra: Un framework de experimentación](#MLFlow-+-Hydra:-Un-framework-de-experimentación)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec3e180",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e85a7cb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ¿Qué es MLFlow?\n",
    "\n",
    "Es una [plataforma de código abierto para trabajar con el **ciclo de vida en aplicaciones de aprendizaje automático**](https://mlflow.org). Entre sus funcionalidad se destacan:\n",
    "\n",
    "* Lleva registro de experimentos (local o remoto), para comparar hiperparémetros y resultados.\n",
    "* Empaqueta código de manera que sea posible de compartir y reutilizar.\n",
    "* Administra y despliega modelos de distintos frameworks de Machine Learning para servirlos online.\n",
    "* Provee un modelo central para colaborar durante el desarrollo de una aplicación de aprendizaje automático.\n",
    "\n",
    "En esta charla nos centraremos en el primer punto, i.e. el registro de experimentos, sin embargo les invito a leer la [documentación](https://mlflow.org/docs/latest/index.html) sobre los demás temas, si les interesan, la cuál es muy buena."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b6299a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Instalación de MLFlow\n",
    "\n",
    "Para instalar con `pip`:\n",
    "\n",
    "    $ pip install mlflow\n",
    "\n",
    "Para instalar con `conda`:\n",
    "\n",
    "    $ conda install mlflow -c conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ec960d",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e5d82b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Corriendo un experimento sencillo\n",
    "\n",
    "Vamos a trabajar con el problema de clasificación de calidad de vinos del [conjunto de datos del repositorio UCI](https://archive.ics.uci.edu/ml/datasets/Wine), que se encuentra disponible en el archivo `./data/wines-data.csv`. Este ya está dividido en `train/test/validation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e3ffe",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/wines-data.csv')\n",
    "display(data.head())\n",
    "\n",
    "train_data = data.loc[data['Split'] == 'train'].iloc[:, 2:].values\n",
    "train_target = data.loc[data['Split'] == 'train', 'Quality'].values\n",
    "\n",
    "val_data = data.loc[data['Split'] == 'validation'].iloc[:, 2:].values\n",
    "val_target = data.loc[data['Split'] == 'validation', 'Quality'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30f0b30",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def run_experiment(solver, penalty, C):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params({\n",
    "            'solver': solver,\n",
    "            'penalty': penalty,\n",
    "            'C': C\n",
    "        })\n",
    "\n",
    "        clf = LogisticRegression(\n",
    "            penalty=penalty,\n",
    "            solver=solver,\n",
    "            C=C\n",
    "        ).fit(train_data, train_target)\n",
    "\n",
    "        val_preds = clf.predict(val_data)\n",
    "        accuracy = accuracy_score(val_target, val_preds)\n",
    "        f1_per_class = f1_score(val_target, val_preds, average=None)\n",
    "        f1_macro = pd.Series(f1_per_class).mean()\n",
    "\n",
    "        mlflow.log_metrics({\n",
    "            'accuracy': accuracy,\n",
    "            'f1_macro': f1_macro\n",
    "        })\n",
    "\n",
    "        for class_idx, class_f1 in enumerate(f1_per_class, start=1):\n",
    "            mlflow.log_metric(f\"f1_quality_{class_idx}\", class_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4d5647",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Experiment vs. Run\n",
    "\n",
    "MLFlow tiene dos entidades principales a la hora de trabajar. Los [`experiments`](https://mlflow.org/docs/latest/tracking.html#organizing-runs-in-experiments) y los [`runs`](https://mlflow.org/docs/latest/tracking.html#logging-data-to-runs). En sí, al correr un experimento, lo que hacemos es hacer un *run* donde hace el registro de los datos (parámetros y métricas), y varios de estos *run* (con diferentes datos) conforman un experimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1124026e",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "solver = 'liblinear'  # Type of solver for the LR algorithm\n",
    "penalty = 'l2'  # Type of regularization penalty (depends on the solver)\n",
    "C = 1/1e-3  # This is the inverse of the regularization parameter\n",
    "\n",
    "run_experiment(solver, penalty, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11a7468",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Revisando la UI de MLFlow\n",
    "\n",
    "Una vez que corremos el experimento, el siguiente punto es la verificación de los resultados en la UI nativa de MLFlow. Para ello basta con iniciar dicha UI en una terminal mediante el siguiente comando:\n",
    "\n",
    "    (venv) $ mlflow ui # [--host 127.0.0.1] [--port 5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b6632f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Realizando una búsqueda exhaustiva\n",
    "\n",
    "Correr un experimento y hacer un registro de parámetros y métricas es sólo lo básico que ofrece el `Tracking` de MLFlow. La verdadera potencia reside en poder realizar varios runs para comparar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e4b98c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "param_grid = {\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [1/1e-2, 1/1e-3, 1/1e-4]\n",
    "}\n",
    "\n",
    "for parameters in ParameterGrid(param_grid):\n",
    "    run_experiment(**parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e3a1fc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Personalizando experiments y runs\n",
    "\n",
    "Por defecto, MLFlow guarda todos los runs que se corren en un experimento por defecto que suele llevar el nombre `Default` y el ID `0`. Cuando queremos correr distintos experimentos (e.g. para distintos conjuntos de datos o para distintos tipos de clasificador), podemos hacer múltiples experimentos configurando correctamente los parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071b800d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def run_experiment(solver, penalty, C, run_name):\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.log_params({\n",
    "            'solver': solver,\n",
    "            'penalty': penalty,\n",
    "            'C': C\n",
    "        })\n",
    "\n",
    "        clf = LogisticRegression(\n",
    "            penalty=penalty,\n",
    "            solver=solver,\n",
    "            C=C\n",
    "        ).fit(train_data, train_target)\n",
    "\n",
    "        val_preds = clf.predict(val_data)\n",
    "        accuracy = accuracy_score(val_target, val_preds)\n",
    "        f1_per_class = f1_score(val_target, val_preds, average=None)\n",
    "        f1_macro = pd.Series(f1_per_class).mean()\n",
    "\n",
    "        mlflow.log_metrics({\n",
    "            'accuracy': accuracy,\n",
    "            'f1_macro': f1_macro\n",
    "        })\n",
    "\n",
    "        for class_idx, class_f1 in enumerate(f1_per_class, start=1):\n",
    "            mlflow.log_metric(f\"f1_quality_{class_idx}\", class_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddac924",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(experiment_name='personalized_experiment')\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    run_name = f\"solver:{params['solver']}_penalty:{params['penalty']}_reg:{params['C']}\"\n",
    "    run_experiment(**params, run_name=run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf5a4ba",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Editando la descripción\n",
    "\n",
    "- Una de las cosas que permite la UI de MLFlow es editar una descripción sobre determinada corrida de un experimento. \n",
    "- Esto puede ser útil para guardar cosas más complejas que una métrica, pero que no requieran tanto espacio como un artefacto y sean fáciles de acceder. \n",
    "- Para ello podemos reescribir un `tag` especial de MLFlow que indica que las notas de determinada corrida se guardarán con ciertos valores. \n",
    "  - Por ejemplo, podemos utilizarlos para guardar el **reporte de clasificación** de Scikit-Learn (¡y funciona con Markdown!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc27894",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def run_experiment(solver, penalty, C):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params({\n",
    "            'solver': solver,\n",
    "            'penalty': penalty,\n",
    "            'C': C\n",
    "        })\n",
    "\n",
    "        clf = LogisticRegression(\n",
    "            penalty=penalty,\n",
    "            solver=solver,\n",
    "            C=C\n",
    "        ).fit(train_data, train_target)\n",
    "\n",
    "        val_preds = clf.predict(val_data)\n",
    "        accuracy = accuracy_score(val_target, val_preds)\n",
    "        f1_per_class = f1_score(val_target, val_preds, average=None, zero_division=0)\n",
    "        f1_macro = pd.Series(f1_per_class).mean()\n",
    "\n",
    "        mlflow.log_metrics({\n",
    "            'accuracy': accuracy,\n",
    "            'f1_macro': f1_macro\n",
    "        })\n",
    "\n",
    "        for class_idx, class_f1 in enumerate(f1_per_class, start=1):\n",
    "            mlflow.log_metric(f\"f1_quality_{class_idx}\", class_f1)\n",
    "\n",
    "        run_report = classification_report(val_target, val_preds, zero_division=0)\n",
    "        mlflow.set_tag(\"mlflow.note.content\", \n",
    "                       \"Reporte de clasificación para esta corrida:\\n\"\n",
    "                       f\"```\\n{run_report}\\n```\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664322bc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(experiment_name='description_experiment')\n",
    "\n",
    "for parameters in ParameterGrid(param_grid):\n",
    "    run_experiment(**parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184b2526",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Artefactos en MLFlow\n",
    "\n",
    "- Una de las características más interesantes que brinda MLFlow es la capacidad de guardar **artefactos**. \n",
    "    - Un artefacto es un archivo (o directorio) que existen localmente y puede ser copiado a una unidad de almacenamiento definida por MLFlow. \n",
    "    - Dicha unidad puede ser local o remote (e.g. un Amazon S3). \n",
    "- En particular son útiles para guardar información extra que a veces puede ser necesaria.\n",
    "    - Un archivo de predicciones con información extra como la probabilidad de cada clase.\n",
    "    - Un archivo de predicciones erróneas que puede ser utilizado luego en análisis de error detallado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b770d4a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "def run_experiment(solver, penalty, C):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params({\n",
    "            'solver': solver,\n",
    "            'penalty': penalty,\n",
    "            'C': C\n",
    "        })\n",
    "\n",
    "        clf = LogisticRegression(\n",
    "            penalty=penalty,\n",
    "            solver=solver,\n",
    "            C=C\n",
    "        ).fit(train_data, train_target)\n",
    "\n",
    "        # Obtengo la probabilidad por clase de cada una de las instancias\n",
    "        val_preds_probs = clf.predict_proba(val_data)\n",
    "        val_preds = clf.predict(val_data)\n",
    "\n",
    "        accuracy = accuracy_score(val_target, val_preds)\n",
    "        f1_per_class = f1_score(val_target, val_preds, average=None)\n",
    "        f1_macro = pd.Series(f1_per_class).mean()\n",
    "\n",
    "        mlflow.log_metrics({\n",
    "            'accuracy': accuracy,\n",
    "            'f1_macro': f1_macro\n",
    "        })\n",
    "\n",
    "        for class_idx, class_f1 in enumerate(f1_per_class, start=1):\n",
    "            mlflow.log_metric(f\"f1_quality_{class_idx}\", class_f1)\n",
    "\n",
    "        predictions_features = pd.DataFrame(val_data, columns=data.columns[2:])\n",
    "        target_predictions = pd.Series(val_target, name=\"Quality\")\n",
    "        predictions_probs = pd.DataFrame(val_preds_probs,\n",
    "                                         columns=[f\"Quality {i+1} Prediction Probability\" for i in range(3)])\n",
    "        predictions_dataset = pd.concat([target_predictions, predictions_probs, predictions_features],\n",
    "                                        axis=1)\n",
    "        with TemporaryDirectory() as tmpdir:\n",
    "            predictions_path = Path(tmpdir) / 'predictions.csv'\n",
    "            predictions_dataset.to_csv(predictions_path, index=False)\n",
    "            mlflow.log_artifact(predictions_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5944a0b1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(experiment_name='artifact_experiment')\n",
    "\n",
    "for parameters in ParameterGrid(param_grid):\n",
    "    run_experiment(**parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505e61c7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hydra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d288af09",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ¿Qué es hydra?\n",
    "\n",
    "Es un [framework open source para **simplificar el desarrollo de aplicaciones de investigación y aplicaciones de configuración compleja**](https://hydra.cc/). Algunas características:\n",
    "\n",
    "* Configuración jerárquica compuesta de múltiples fuentes.\n",
    "* La configuración puede ser especificada y sobre-escrita desde la línea de comando.\n",
    "* Correr la aplicación de manera local o remota.\n",
    "* Correr múltiples veces con diferentes argumentos desde un sólo comando.\n",
    "\n",
    "Si bien en esta charla nos concentraremos en los dos primeros puntos, pueden leer la [documentación](https://hydra.cc/docs/intro/) para explorar todas las posibilidades que ofrece."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f58917b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Instalación de Hydra\n",
    "\n",
    "Para instalar con `pip`:\n",
    "\n",
    "    $ pip install hydra-core --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b308392",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Una aplicación sencilla\n",
    "\n",
    "Empezamos mostrando una aplicación sencilla con un archivo de configuración. Hydra no se puede correr (al menos no trivialmente) en un notebook, así que armamos un pequeño paquete para correrlo. Este poseerá el programa principal y un directorio con la configuración:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb95749d",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;27m./hydra_basic/\u001b[0m\r\n",
      "├── \u001b[38;5;27mconf\u001b[0m\r\n",
      "│   └── config.yaml\r\n",
      "└── experiment.py\r\n",
      "\r\n",
      "1 directory, 2 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree ./hydra_basic/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018df469",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Configuración\n",
    "\n",
    "El archivo de configuración es un YAML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0784f55c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36minput\u001b[0m:\u001b[36m\u001b[0m\r\n",
      "\u001b[36m  data_file\u001b[0m:\u001b[32m ./data/wines-data.csv\u001b[0m\r\n",
      "\u001b[32m\u001b[0m\u001b[36mtrain\u001b[0m:\u001b[36m\u001b[0m\r\n",
      "\u001b[36m  split\u001b[0m:\u001b[32m train\u001b[0m\r\n",
      "\u001b[32m  \u001b[0m\u001b[36mmodel\u001b[0m:\u001b[36m\u001b[0m\r\n",
      "\u001b[36m    penalty\u001b[0m:\u001b[32m l2\u001b[0m\r\n",
      "\u001b[32m    \u001b[0m\u001b[36msolver\u001b[0m:\u001b[32m liblinear\u001b[0m\r\n",
      "\u001b[32m    \u001b[0m\u001b[36mC\u001b[0m:\u001b[95m 1000\u001b[0m\r\n",
      "\u001b[95m\u001b[0m\u001b[36mevaluation\u001b[0m:\u001b[36m\u001b[0m\r\n",
      "\u001b[36m  split\u001b[0m:\u001b[32m validation\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!yq -C . < ./hydra_basic/conf/config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ec0e68",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Programa principal\n",
    "\n",
    "Una aplicación Hydra se define mediante el decorador `@hydra.main` que es el que lee el archivo de configuración y lo transforma en un [`DictConfig`](https://omegaconf.readthedocs.io/en/2.2_branch/) (i.e. un diccionario de configuración)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6524ea2a",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "@hydra.main(config_path='conf', config_name='config', version_base=None)\n",
    "def main(cfg: DictConfig):\n",
    "    print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493de9d5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ejecutando el programa\n",
    "\n",
    "La celda anterior sólo es de muestra, en general no tiene sentido correr hydra desde un notebook. En la siguiente celda corremos la [aplicación de muestra](/edit/hydra_basic/experiment.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe859b7",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!python ./hydra_basic/experiment.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c48ceb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Logs del programa\n",
    "\n",
    "La aplicación en realidad se corre bajo un nuevo directorio que se crea al momento de ejecutar el programa y está por defecto en la dirección `./outputs/DATA/HOUR/`. En este caso podemos ver que una vez terminado de correr el programa tenemos un archivo con los logs del mismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccff114",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree ./outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49cd409",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find ./outputs -type f -name \"*.log\" -exec cat {} \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b417bcb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Personalizando configuración via CLI\n",
    "\n",
    "Parte de la potencia de Hydra reside en poder cambiar la configuración sin necesidad de modificar el archivo, y sólo mediante una interfaz de línea de comandos (CLI). Existen 3 opciones a la hora de sobreescribir:\n",
    "\n",
    "- Sobreescribir un parámetro existente\n",
    "- Crear un nuevo parámetro\n",
    "- Realizar un *upsert* (i.e. sobreescribir si existe y crearlo sino).\n",
    "\n",
    "A la hora de correr se hace escribiendo la configuración como una *lista de puntos*. Si se quiere agregar un nuevo valor, se pone el prefijo `+`, si se quiere hacer un *upsert* es `++`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa8bc15",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "python ./hydra_basic/experiment.py \\\n",
    "    evaluation.split=test \\\n",
    "    +train.model.max_iter=10000 \\\n",
    "    ++train.model.solver=saga \\\n",
    "    ++train.model.random_state=42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66afe16e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Archivo de configuración avanzado\n",
    "\n",
    "Más allá de la base de configuración, hydra también soporta otras cosas en sus archivos de configuración que permiten mayor flexibilidad. Entre estas destacan:\n",
    "\n",
    "* **Configuraciones requeridas:** Aquellas cuyos valores están faltantes y se requieren para continuar la computación. Estas se determinan con el valor especial `???`.\n",
    "* **Interpolación de valores:** Cuando un valor de alguna configuración requiere de otro valor se pueden utilizar interpolaciones y acceder a la configuración requerida. Esto se hace mediante `${path.a.la.config}`.\n",
    "* **Resolvers:** Estos definen funciones que se ejecutarán en el script python en tiempo de ejecución. Es algo muy poderoso, pero que también se debe utilizar con cuidado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6704c98",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36minput\u001b[0m:\u001b[36m\u001b[0m\r\n",
      "\u001b[36m  data_file\u001b[0m:\u001b[32m ???\u001b[0m\r\n",
      "\u001b[32m  \u001b[0m\u001b[36mrandom_seed\u001b[0m:\u001b[95m 42\u001b[0m\r\n",
      "\u001b[95m\u001b[0m\u001b[36mtrain\u001b[0m:\u001b[36m\u001b[0m\r\n",
      "\u001b[36m  split\u001b[0m:\u001b[32m train\u001b[0m\r\n",
      "\u001b[32m  \u001b[0m\u001b[36mmodel\u001b[0m:\u001b[36m\u001b[0m\r\n",
      "\u001b[36m    penalty\u001b[0m:\u001b[32m l2\u001b[0m\r\n",
      "\u001b[32m    \u001b[0m\u001b[36msolver\u001b[0m:\u001b[32m liblinear\u001b[0m\r\n",
      "\u001b[32m    \u001b[0m\u001b[36mC\u001b[0m:\u001b[32m ${eval:1 / 1e-3}\u001b[0m\r\n",
      "\u001b[32m    \u001b[0m\u001b[36mrandom_state\u001b[0m:\u001b[32m ${input.random_seed}\u001b[0m\r\n",
      "\u001b[32m\u001b[0m\u001b[36mevaluation\u001b[0m:\u001b[36m\u001b[0m\r\n",
      "\u001b[36m  split\u001b[0m:\u001b[32m validation\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!yq -C . < ./hydra_advanced/conf/config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9d46db",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ejecutando el programa\n",
    "\n",
    "Si revisamos la nueva [aplicación de muestra](/edit/hydra_advanced/experiment.py), veremos que tenemos una línea en particular que registra un nuevo *resolver* que lo que hace es evaluar la operación. En este caso, la única configuración que la utiliza es `train.split.C`. Por otro lado, requerimos del path al archivo de datos en este caso, y además vemos que la configuración `input.random_seed` es copiada en `train.model.random_state`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3394c62",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!python ./hydra_advanced/experiment.py input.data_file=./data/wines-data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9926d4b5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Configuraciones complejas\n",
    "\n",
    "Hydra permite ir más lejos y hacer configuraciones más complejas a través de múltiples archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1201eeb7",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;27m./hydra_complex/\u001b[0m\r\n",
      "├── \u001b[38;5;27mconf\u001b[0m\r\n",
      "│   ├── config.yaml\r\n",
      "│   └── \u001b[38;5;27mtrain\u001b[0m\r\n",
      "│       └── \u001b[38;5;27mmodel\u001b[0m\r\n",
      "│           ├── logreg.yaml\r\n",
      "│           └── svm.yaml\r\n",
      "└── experiment.py\r\n",
      "\r\n",
      "3 directories, 4 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree ./hydra_complex/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c658bab4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Modelos con configuraciones propias\n",
    "\n",
    "En nuestro ejemplo modificamos el parámetro `train.model` del archivo [`config.yaml`](/edit/hydra_complex/conf/config.yaml) y lo sustituimos por configuraciones propias en `conf/train/model`. Tenemos dos modelos y parámetros para los mismos: [`logreg.yaml`](/edit/hydra_complex/conf/train/model/logreg.yaml) y [`svm.yaml`](/edit/hydra_complex/conf/train/model/svm.yaml)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f741411",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mdefaults\u001b[0m:\r\n",
      "  -\u001b[32m _self_\u001b[0m\r\n",
      "\u001b[32m  \u001b[0m-\u001b[36m train/model\u001b[0m:\u001b[32m logreg\u001b[0m\r\n",
      "\u001b[32m\u001b[0m\u001b[36minput\u001b[0m:\u001b[36m\u001b[0m\r\n",
      "\u001b[36m  data_file\u001b[0m:\u001b[32m ???\u001b[0m\r\n",
      "\u001b[32m  \u001b[0m\u001b[36mrandom_seed\u001b[0m:\u001b[95m 42\u001b[0m\r\n",
      "\u001b[95m\u001b[0m\u001b[36mtrain\u001b[0m:\u001b[36m\u001b[0m\r\n",
      "\u001b[36m  split\u001b[0m:\u001b[32m train\u001b[0m\r\n",
      "\u001b[32m\u001b[0m\u001b[36mevaluation\u001b[0m:\u001b[36m\u001b[0m\r\n",
      "\u001b[36m  split\u001b[0m:\u001b[32m validation\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!yq -C . < ./hydra_complex/conf/config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44ed6974",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mmodule\u001b[0m:\u001b[32m ${eval:LogisticRegression}\u001b[0m\r\n",
      "\u001b[32m\u001b[0m\u001b[36mparams\u001b[0m:\u001b[36m\u001b[0m\r\n",
      "\u001b[36m  penalty\u001b[0m:\u001b[32m l2\u001b[0m\r\n",
      "\u001b[32m  \u001b[0m\u001b[36msolver\u001b[0m:\u001b[32m liblinear\u001b[0m\r\n",
      "\u001b[32m  \u001b[0m\u001b[36mC\u001b[0m:\u001b[32m ${eval:1 / 1e-3}\u001b[0m\r\n",
      "\u001b[32m  \u001b[0m\u001b[36mrandom_state\u001b[0m:\u001b[32m ${input.random_seed}\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!yq -C . < ./hydra_complex/conf/train/model/logreg.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e08a3639",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mmodule\u001b[0m:\u001b[32m ${eval:LinearSVC}\u001b[0m\r\n",
      "\u001b[32m\u001b[0m\u001b[36mparams\u001b[0m:\u001b[36m\u001b[0m\r\n",
      "\u001b[36m  penalty\u001b[0m:\u001b[32m l2\u001b[0m\r\n",
      "\u001b[32m  \u001b[0m\u001b[36mloss\u001b[0m:\u001b[32m hinge\u001b[0m\r\n",
      "\u001b[32m  \u001b[0m\u001b[36mC\u001b[0m:\u001b[32m ${eval:1 / 1e-3}\u001b[0m\r\n",
      "\u001b[32m  \u001b[0m\u001b[36mrandom_state\u001b[0m:\u001b[32m ${input.random_seed}\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!yq -C . < ./hydra_complex/conf/train/model/svm.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5d3edb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ejecutando la aplicación\n",
    "\n",
    "* Básicamente, lo que cambia es que en esta [nueva versión de la aplicación](/edit/hydra_complex/experiment.py), podemos elegir el tipo de clasificador (de las configuraciones disponibles, claro está) que queremos utilizar. \n",
    "* Por defecto, se utilizarán los datos de la configuración `logreg.yaml` puesto que se define en el archivo de configuración principal bajo la configuración especial `defaults`.\n",
    "* El parámetro `_self_` indica la prioridad en caso de que haya configuraciones compartidas entre el archivo de configuración principal y alguno de los archivos por defecto, si `_self_` está al final entonces cualquier configuración compartida toma el valor del archivo de configuración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e444c7e",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!python ./hydra_complex/experiment.py input.data_file=./data/wines-data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44847d61",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Si queremos entrenar con el modelo `svm`, lo aclaramos al correr la configuración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d0757e",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "python ./hydra_complex/experiment.py \\\n",
    "    input.data_file=./data/wines-data.csv \\\n",
    "    train/model=svm \\\n",
    "    train.model.params.C='${eval:1/1e-4}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c7545c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MLFlow + Hydra: Un framework de experimentación para Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8471b28d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ¿Cómo es mi framework de experimentación?\n",
    "\n",
    "En el día a día utilizo MLFlow y Hydra para realizar una gran cantidad de experimentos. Para poder llevar registro de lo que busco con dichos experimentos, con la ayuda de Hydra y MLFlow diseñé un patrón que me sirve para organizarme:\n",
    "\n",
    "* Cada experimento de MLFlow define una hipótesis de experimentación.\n",
    "* Utilizo los nombres y, sobre todo, las descripciones de los experimentos para establecer la hipótesis que estoy investigando y no olvidarla. De esta forma entiendo cuál era el objetivo de un conjunto de experimentos realizados.\n",
    "    * E.g. \"Hipótesis: Utilizar más capas en el perceptrón multicapa produce overfitting.\"\n",
    "* Los *runs* definen las configuraciones para rechazar o no dicha hipótesis.\n",
    "* En cada *run* guardo información importante (en el nombre o descripción) de lo más interesante de dicho *run*.\n",
    "    * E.g. dejo en claro el número de capas en el nombre y/o la descripción para poder diferenciarlo fácilmente.\n",
    "* Durante el proceso de entrenamiento utilizo `mlflow.log_artifacts` y puedo guardar la configuración total y/o el modelo.\n",
    "* Finalizados los runs, puedo ver si la hipótesis se rechaza.\n",
    "    * Puedo utilizar la comparación (scatterplot) también para ver que features hacen diferencias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dfd597",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Ejemplo de una aplicación de experimentación\n",
    "\n",
    "En el directorio `./mlflow_hydra` hay una aplicación completa de cómo utilizo yo MLFlow + Hydra (+ bonus de [Pytorch Lighning](https://pytorch-lightning.readthedocs.io/en/latest/)) en mi día a día."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ec6cb4b",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;27m./mlflow_hydra/\u001b[0m\r\n",
      "├── \u001b[38;5;27mconf\u001b[0m\r\n",
      "│   └── config.yaml\r\n",
      "├── experiment.py\r\n",
      "├── __init__.py\r\n",
      "├── model.py\r\n",
      "└── utils.py\r\n",
      "\r\n",
      "1 directory, 5 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree ./mlflow_hydra/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cdbf1c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### El archivo de configuración\n",
    "\n",
    "En el [archivo de configuración](/edit/mlflow_hydra/conf/config.yaml) tenemos dos secciones principales:\n",
    "\n",
    "1. La sección `input` define cuestiones más del experimento, en particular, además del path al archivo de datos que voy a estar utilizando, explicito cosas como la hipótesis (que es el nombre de un experimento en MLFlow), la descripción de dicha hipótesis y el nombre del `run` de MLFLow que utilizaré para destacar la información (parámetros) más importantes para un fácil acceso.\n",
    "2. En la sección `train` tengo los detalles de implementación que usaré en el experimento, i.e. los hiperparámetros a modificar a lo largo de los diferentes `run`s de dicho experimento que ayudarán a rechazar o no la hipótesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d42848f",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36minput\u001b[0m:\u001b[36m\u001b[0m\r\n",
      "\u001b[36m  data_file\u001b[0m:\u001b[32m ???\u001b[0m\r\n",
      "\u001b[32m  \u001b[0m\u001b[36mrun_name\u001b[0m:\u001b[32m ???\u001b[0m\r\n",
      "\u001b[32m  \u001b[0m\u001b[36mexperiment_name\u001b[0m:\u001b[32m Hypothesis 1\u001b[0m\r\n",
      "\u001b[32m  \u001b[0m\u001b[36mexperiment_description\u001b[0m:\u001b[32m \"**Hypothesis 1:** More layers increase the overfitting\"\u001b[0m\u001b[36m\u001b[0m\r\n",
      "\u001b[36mtrain\u001b[0m:\u001b[36m\u001b[0m\r\n",
      "\u001b[36m  test_evaluation\u001b[0m:\u001b[95m false\u001b[0m\r\n",
      "\u001b[95m  \u001b[0m\u001b[36mfeature_scaling\u001b[0m:\u001b[95m true\u001b[0m\r\n",
      "\u001b[95m  \u001b[0m\u001b[36mbatch_size\u001b[0m:\u001b[95m 16\u001b[0m\r\n",
      "\u001b[95m  \u001b[0m\u001b[36mepochs\u001b[0m:\u001b[95m 10\u001b[0m\r\n",
      "\u001b[95m  \u001b[0m\u001b[36mearly_stop\u001b[0m:\u001b[95m 3\u001b[0m\r\n",
      "\u001b[95m  \u001b[0m\u001b[36mmodel\u001b[0m:\u001b[36m\u001b[0m\r\n",
      "\u001b[36m    layers\u001b[0m: [\u001b[95m64\u001b[0m]\u001b[36m\u001b[0m\r\n",
      "\u001b[36m    learning_rate\u001b[0m:\u001b[32m 1e-3\u001b[0m\r\n",
      "\u001b[32m    \u001b[0m\u001b[36ml2_lambda\u001b[0m:\u001b[32m 1e-5\u001b[0m\r\n",
      "\u001b[32m    \u001b[0m\u001b[36mactivation\u001b[0m:\u001b[32m ${eval:torch.nn.ReLU}\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!yq -C . < ./mlflow_hydra/conf/config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdfe251",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### La aplicación del experimento\n",
    "\n",
    "La [aplicación del experimento](/edit/mlflow_hydra/experiment.py) consta de una función `main` que se encargará de hacer el setup inicial de MLFLow, definiendo el nombre del experimento, la descripción, y guardando cosas como los hiperparámetros y el archivo de configuración. Además, la función `run_experiment` que simplemente corre el modelo de Pytorch Lightning (recomiendo leer la [documentación oficial](https://pytorch-lightning.readthedocs.io/en/latest/starter/introduction.html) para entender en más detalle el ejemplo), que tiene la habilidad de hacer un [binding con el mismo MLFlow](https://pytorch-lightning.readthedocs.io/en/latest/visualize/experiment_managers.html#mlflow) para llevar registro de como el modelo va aprendiendo a lo largo de las distintas épocas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec2ff47",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Corriendo iteraciones del experimento para verificar la hipótesis\n",
    "\n",
    "Por último, podemos correr varios experimentos con distintos hiperparámetros (en este caso el único hiperparámetro que importa es el número de capas ocultas) para ver si la hipótesis se puede rechazar o no. Para eso podemos utilizar distintos métodos, en lo personal prefiero hacerlo directamente via BASH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d821f1d9",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "LAYERS=\"[] [64] [64,64] [64,64,64]\"\n",
    "\n",
    "for layers in $LAYERS\n",
    "do\n",
    "    python -m mlflow_hydra.experiment \\\n",
    "        input.data_file=./data/wines-data.csv \\\n",
    "        input.run_name=\\\"layers:$layers\\\" \\\n",
    "        train.model.layers=$layers\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa5a24e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"text-align:center;\">¡Muchas Gracias!</h1>\n",
    "\n",
    "<h2 style=\"text-align:center;\">¿Preguntas?</h2>\n",
    "\n",
    "* Twitter: https://twitter.com/crscardellino\n",
    "* LinkedIn: https://www.linkedin.com/in/crscardellino\n",
    "* Página Personal: https://crscardellino.ar\n",
    "* GitHub: https://github.com/crscardellino/\n",
    "* Código de la presentación: https://github.com/crscardellino/data-ar-mlflow-hydra"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
